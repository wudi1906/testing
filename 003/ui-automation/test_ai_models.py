#!/usr/bin/env python3
"""
AIæ¨¡å‹æµ‹è¯•å¯åŠ¨è„šæœ¬
å¿«é€ŸéªŒè¯æ‰€æœ‰é…ç½®çš„AIæ¨¡å‹æ˜¯å¦å¯ç”¨
"""
import sys
import os
import asyncio
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent.absolute()
backend_dir = current_dir / "backend"
sys.path.insert(0, str(backend_dir))

from app.tests.test_ai_models import run_ai_model_tests
from loguru import logger

def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logger.remove()  # ç§»é™¤é»˜è®¤handler
    logger.add(
        sys.stdout,
        level="INFO",
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | {message}",
        colorize=True
    )

async def main():
    """ä¸»å‡½æ•°"""
    setup_logging()
    
    logger.info("ğŸš€ å¯åŠ¨AIæ¨¡å‹å¯ç”¨æ€§æµ‹è¯•...")
    logger.info(f"ğŸ“‚ é¡¹ç›®ç›®å½•: {current_dir}")
    
    try:
        # è¿è¡Œæµ‹è¯•
        results = await run_ai_model_tests()
        
        # ç»Ÿè®¡ç»“æœ
        total_models = len(results)
        successful_count = sum(1 for r in results.values() if r["success"])
        failed_count = total_models - successful_count
        
        logger.info(f"\nğŸ“Š æµ‹è¯•å®Œæˆç»Ÿè®¡:")
        logger.info(f"   æ€»æ¨¡å‹æ•°: {total_models}")
        logger.info(f"   æˆåŠŸ: {successful_count} ä¸ª")
        logger.info(f"   å¤±è´¥: {failed_count} ä¸ª")
        logger.info(f"   æˆåŠŸç‡: {(successful_count/total_models*100):.1f}%")
        
        if successful_count > 0:
            logger.info("\nğŸ‰ ç³»ç»Ÿå¯ä»¥æ­£å¸¸è¿è¡Œï¼")
            return True
        else:
            logger.error("\nâš ï¸ æ‰€æœ‰æ¨¡å‹éƒ½ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®ï¼")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
