"""
AIæ¨¡å‹å¯ç”¨æ€§æµ‹è¯•
æµ‹è¯•æ‰€æœ‰é…ç½®çš„AIå¤§æ¨¡å‹æ˜¯å¦å¯æ­£å¸¸ä½¿ç”¨
"""
import asyncio
import aiohttp
import json
import time
from typing import Dict, List, Optional, Tuple
from loguru import logger
from app.core.config import settings


class AIModelTester:
    """AIæ¨¡å‹æµ‹è¯•å™¨ - éªŒè¯æ‰€æœ‰AIæ¨¡å‹çš„å¯ç”¨æ€§å’Œæ€§èƒ½"""
    
    def __init__(self):
        self.test_results = {}
        self.models_config = self._get_all_models_config()
        
    def _get_all_models_config(self) -> Dict:
        """è·å–æ‰€æœ‰AIæ¨¡å‹é…ç½®"""
        return {
            "qwen_vl": {
                "name": "é˜¿é‡Œé€šä¹‰åƒé—®è§†è§‰ç‰ˆ (æ¨è - è§†è§‰ä»»åŠ¡æœ€ä½³)",
                "api_key": getattr(settings, 'QWEN_VL_API_KEY', ''),
                "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
                "model": "qwen-vl-plus",
                "provider": "openai-compatible",
                "priority": 1,  # æœ€é«˜ä¼˜å…ˆçº§
                "cost_rating": "â­â­â­â­â­",  # æ€§ä»·æ¯”æœ€é«˜
                "use_case": "UIè‡ªåŠ¨åŒ–è§†è§‰è¯†åˆ«ã€OCRã€å›¾åƒç†è§£"
            },
            "qwen": {
                "name": "é˜¿é‡Œé€šä¹‰åƒé—®æ–‡æœ¬ç‰ˆ",
                "api_key": getattr(settings, 'QWEN_API_KEY', ''),
                "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
                "model": "qwen-plus",
                "provider": "openai-compatible",
                "priority": 2,
                "cost_rating": "â­â­â­â­â­",
                "use_case": "æ–‡æœ¬ç”Ÿæˆã€ä»£ç ç”Ÿæˆã€é€»è¾‘æ¨ç†"
            },
            "glm_4v": {
                "name": "æ™ºè°±AI GLM-4V (å¤‡é€‰ - æ€§èƒ½ä¼˜ç§€)",
                "api_key": getattr(settings, 'GLM_API_KEY', ''),
                "base_url": "https://open.bigmodel.cn/api/paas/v4",
                "model": "glm-4v",
                "provider": "openai-compatible",
                "priority": 3,
                "cost_rating": "â­â­â­â­",
                "use_case": "å¤šæ¨¡æ€ç†è§£ã€å›¾æ–‡æ··åˆä»»åŠ¡"
            },
            "deepseek_vl": {
                "name": "DeepSeek VL (æ–‡æœ¬+è§†è§‰é«˜æ€§ä»·æ¯”)",
                "api_key": getattr(settings, 'DEEPSEEK_API_KEY', ''),
                "base_url": "https://api.deepseek.com/v1",
                "model": "deepseek-vl",
                "provider": "openai-compatible",
                "priority": 4,
                "cost_rating": "â­â­â­â­â­",
                "use_case": "ä»£ç ç†è§£ã€å¤æ‚æ¨ç†ã€æŠ€æœ¯æ–‡æ¡£"
            },
            "deepseek_chat": {
                "name": "DeepSeek Chat (çº¯æ–‡æœ¬é«˜æ€§ä»·æ¯”)",
                "api_key": getattr(settings, 'DEEPSEEK_API_KEY', ''),
                "base_url": "https://api.deepseek.com/v1",
                "model": "deepseek-chat",
                "provider": "openai-compatible",
                "priority": 5,
                "cost_rating": "â­â­â­â­â­",
                "use_case": "æ—¥å¸¸å¯¹è¯ã€æ–‡æœ¬å¤„ç†ã€ç®€å•æ¨ç†"
            },
            "ui_tars": {
                "name": "è±†åŒ… UI-TARS (UIè‡ªåŠ¨åŒ–ä¸“ç”¨)",
                "api_key": getattr(settings, 'UI_TARS_API_KEY', ''),
                "base_url": "https://ark.cn-beijing.volces.com/api/v3",
                "model": "doubao-1-5-ui-tars-250428",
                "provider": "openai-compatible",
                "priority": 6,
                "cost_rating": "â­â­â­",
                "use_case": "UIå…ƒç´ è¯†åˆ«ã€ç•Œé¢æ“ä½œã€è‡ªåŠ¨åŒ–æµ‹è¯•"
            },
            "openai_gpt4o": {
                "name": "OpenAI GPT-4O (å…¼å®¹æ€§æœ€å¥½ï¼Œè¾ƒè´µ)",
                "api_key": getattr(settings, 'OPENAI_API_KEY', ''),
                "base_url": "https://api.openai.com/v1",
                "model": "gpt-4o",
                "provider": "openai",
                "priority": 7,
                "cost_rating": "â­â­",
                "use_case": "å¤æ‚æ¨ç†ã€åˆ›æ„å†™ä½œã€é€šç”¨ä»»åŠ¡"
            },
            "gemini": {
                "name": "Google Gemini 2.0 Flash (é¢„ç•™)",
                "api_key": getattr(settings, 'GEMINI_API_KEY', ''),
                "base_url": "https://generativelanguage.googleapis.com/v1beta",
                "model": "gemini-2.0-flash",
                "provider": "google",
                "priority": 8,
                "cost_rating": "â­â­â­",
                "use_case": "å¤šæ¨¡æ€ç†è§£ã€å®æ—¶äº¤äº’"
            }
        }
    
    async def test_model_connectivity(self, model_id: str, config: Dict) -> Tuple[bool, str, float]:
        """æµ‹è¯•å•ä¸ªæ¨¡å‹çš„è¿æ¥æ€§"""
        if not config["api_key"] or config["api_key"].startswith('your-'):
            return False, "APIå¯†é’¥æœªè®¾ç½®", 0.0
            
        start_time = time.time()
        
        try:
            # ç‰¹æ®Šå¤„ç†ä¸åŒçš„APIæ ¼å¼
            if config["provider"] == "google":
                # Gemini APIæ ¼å¼ä¸åŒï¼Œæš‚æ—¶è·³è¿‡å®é™…æµ‹è¯•
                return True, "Gemini APIæ ¼å¼ç‰¹æ®Šï¼Œå¾…é…ç½®", 0.0
            
            # æ„å»ºæµ‹è¯•è¯·æ±‚
            headers = {
                "Authorization": f"Bearer {config['api_key']}",
                "Content-Type": "application/json"
            }
            
            # é’ˆå¯¹ä¸åŒæœåŠ¡å•†è°ƒæ•´è¯·æ±‚æ ¼å¼
            if "dashscope.aliyuncs.com" in config["base_url"]:
                # é˜¿é‡Œäº‘é€šä¹‰åƒé—®æ ¼å¼
                test_data = {
                    "model": config["model"],
                    "messages": [
                        {"role": "user", "content": "Hi"}
                    ],
                    "max_tokens": 5
                }
            elif "open.bigmodel.cn" in config["base_url"]:
                # æ™ºè°±AIæ ¼å¼
                test_data = {
                    "model": config["model"],
                    "messages": [
                        {"role": "user", "content": "Hi"}
                    ],
                    "max_tokens": 5
                }
            elif "api.deepseek.com" in config["base_url"]:
                # DeepSeekæ ¼å¼
                test_data = {
                    "model": config["model"],
                    "messages": [
                        {"role": "user", "content": "Hi"}
                    ],
                    "max_tokens": 5
                }
            elif "ark.cn-beijing.volces.com" in config["base_url"]:
                # è±†åŒ…/UI-TARSæ ¼å¼
                test_data = {
                    "model": config["model"],
                    "messages": [
                        {"role": "user", "content": "Hi"}
                    ],
                    "max_tokens": 5
                }
            else:
                # OpenAIæ ‡å‡†æ ¼å¼
                test_data = {
                    "model": config["model"],
                    "messages": [
                        {"role": "user", "content": "Hi"}
                    ],
                    "max_tokens": 5,
                    "temperature": 0.1
                }
                
            url = f"{config['base_url']}/chat/completions"
            logger.info(f"   ğŸ”— è¯·æ±‚URL: {url}")
            logger.info(f"   ğŸ”‘ APIå¯†é’¥: {config['api_key'][:10]}...")
            
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:
                async with session.post(url, headers=headers, json=test_data) as response:
                    response_time = time.time() - start_time
                    response_text = await response.text()
                    
                    logger.info(f"   ğŸ“¡ å“åº”çŠ¶æ€: {response.status}")
                    logger.info(f"   ğŸ“„ å“åº”å†…å®¹: {response_text[:200]}...")
                    
                    if response.status == 200:
                        try:
                            result = json.loads(response_text)
                            return True, "è¿æ¥æˆåŠŸ", response_time
                        except json.JSONDecodeError:
                            return False, f"å“åº”æ ¼å¼é”™è¯¯: {response_text[:100]}", response_time
                    elif response.status == 401:
                        return False, f"APIå¯†é’¥æ— æ•ˆ: {response_text[:100]}", response_time
                    elif response.status == 403:
                        return False, f"è®¿é—®è¢«æ‹’ç»: {response_text[:100]}", response_time
                    elif response.status == 429:
                        return False, f"è¯·æ±‚é¢‘ç‡é™åˆ¶: {response_text[:100]}", response_time
                    elif response.status == 404:
                        return False, f"ç«¯ç‚¹ä¸å­˜åœ¨: {response_text[:100]}", response_time
                    else:
                        return False, f"HTTP {response.status}: {response_text[:100]}", response_time
                        
        except asyncio.TimeoutError:
            return False, "è¯·æ±‚è¶…æ—¶", time.time() - start_time
        except aiohttp.ClientError as e:
            return False, f"ç½‘ç»œè¿æ¥é”™è¯¯: {str(e)}", time.time() - start_time
        except Exception as e:
            return False, f"æœªçŸ¥é”™è¯¯: {str(e)}", time.time() - start_time
    
    async def test_all_models(self) -> Dict:
        """æµ‹è¯•æ‰€æœ‰æ¨¡å‹"""
        logger.info("ğŸš€ å¼€å§‹AIæ¨¡å‹å¯ç”¨æ€§æµ‹è¯•...")
        
        results = {}
        successful_models = []
        failed_models = []
        
        for model_id, config in self.models_config.items():
            logger.info(f"ğŸ“¡ æµ‹è¯•æ¨¡å‹: {config['name']}")
            
            success, message, response_time = await self.test_model_connectivity(model_id, config)
            
            result = {
                "name": config["name"],
                "model": config["model"],
                "provider": config["provider"],
                "priority": config["priority"],
                "cost_rating": config["cost_rating"],
                "use_case": config["use_case"],
                "success": success,
                "message": message,
                "response_time": response_time,
                "api_key_configured": bool(config["api_key"] and not config["api_key"].startswith('your-'))
            }
            
            results[model_id] = result
            
            if success:
                successful_models.append(model_id)
                logger.info(f"âœ… {config['name']} - æµ‹è¯•æˆåŠŸ ({response_time:.2f}s)")
            else:
                failed_models.append(model_id)
                logger.error(f"âŒ {config['name']} - æµ‹è¯•å¤±è´¥: {message}")
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.test_results = results
        self._generate_test_report(successful_models, failed_models)
        
        return results
    
    def _generate_test_report(self, successful_models: List[str], failed_models: List[str]):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        logger.info("\n" + "="*80)
        logger.info("ğŸ¯ AIæ¨¡å‹æµ‹è¯•æŠ¥å‘Š")
        logger.info("="*80)
        
        # æˆåŠŸçš„æ¨¡å‹
        if successful_models:
            logger.info(f"âœ… å¯ç”¨æ¨¡å‹ ({len(successful_models)}ä¸ª):")
            sorted_successful = sorted(
                [(mid, self.models_config[mid]) for mid in successful_models],
                key=lambda x: x[1]["priority"]
            )
            
            for model_id, config in sorted_successful:
                result = self.test_results[model_id]
                logger.info(f"  ğŸ”¸ {config['name']}")
                logger.info(f"     æ¨¡å‹: {config['model']} | å“åº”æ—¶é—´: {result['response_time']:.2f}s")
                logger.info(f"     æ€§ä»·æ¯”: {config['cost_rating']} | ç”¨é€”: {config['use_case']}")
        
        # å¤±è´¥çš„æ¨¡å‹
        if failed_models:
            logger.info(f"\nâŒ ä¸å¯ç”¨æ¨¡å‹ ({len(failed_models)}ä¸ª):")
            for model_id in failed_models:
                config = self.models_config[model_id]
                result = self.test_results[model_id]
                logger.info(f"  ğŸ”¸ {config['name']}")
                logger.info(f"     é”™è¯¯: {result['message']}")
                logger.info(f"     APIå¯†é’¥: {'å·²é…ç½®' if result['api_key_configured'] else 'æœªé…ç½®'}")
        
        # æ¨èé…ç½®
        logger.info(f"\nğŸ¯ æ¨èé…ç½®:")
        if successful_models:
            # æ‰¾åˆ°ä¼˜å…ˆçº§æœ€é«˜çš„å¯ç”¨æ¨¡å‹
            best_model_id = min(successful_models, key=lambda x: self.models_config[x]["priority"])
            best_config = self.models_config[best_model_id]
            logger.info(f"  ä¸»åŠ›æ¨¡å‹: {best_config['name']}")
            logger.info(f"  åŸå› : ä¼˜å…ˆçº§æœ€é«˜ä¸”å¯ç”¨ï¼Œæ€§ä»·æ¯”: {best_config['cost_rating']}")
            
            # æ‰¾åˆ°æ€§ä»·æ¯”æœ€é«˜çš„æ¨¡å‹
            high_value_models = [
                mid for mid in successful_models 
                if self.models_config[mid]["cost_rating"] == "â­â­â­â­â­"
            ]
            if high_value_models:
                value_model_id = min(high_value_models, key=lambda x: self.models_config[x]["priority"])
                value_config = self.models_config[value_model_id]
                logger.info(f"  æ€§ä»·æ¯”ä¹‹é€‰: {value_config['name']}")
        else:
            logger.error("  âš ï¸ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®ï¼")
        
        logger.info("="*80)
    
    def get_best_available_model(self) -> Optional[str]:
        """è·å–æœ€ä½³å¯ç”¨æ¨¡å‹"""
        if not self.test_results:
            return None
            
        available_models = [
            (model_id, config) for model_id, config in self.test_results.items()
            if config["success"]
        ]
        
        if not available_models:
            return None
            
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œè¿”å›æœ€é«˜ä¼˜å…ˆçº§çš„æ¨¡å‹
        best_model_id = min(available_models, key=lambda x: self.models_config[x[0]]["priority"])[0]
        return best_model_id
    
    def get_models_by_use_case(self, use_case: str) -> List[str]:
        """æ ¹æ®ç”¨é€”è·å–æ¨èæ¨¡å‹"""
        if not self.test_results:
            return []
            
        matching_models = []
        for model_id, result in self.test_results.items():
            if result["success"] and use_case.lower() in result["use_case"].lower():
                matching_models.append(model_id)
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        return sorted(matching_models, key=lambda x: self.models_config[x]["priority"])


async def run_ai_model_tests():
    """è¿è¡ŒAIæ¨¡å‹æµ‹è¯•çš„ä¸»å‡½æ•°"""
    tester = AIModelTester()
    
    logger.info("ğŸ” AIæ¨¡å‹å¯ç”¨æ€§æµ‹è¯•å¼€å§‹...")
    results = await tester.test_all_models()
    
    # è·å–æ¨èé…ç½®
    best_model = tester.get_best_available_model()
    if best_model:
        logger.info(f"ğŸ¯ æ¨èä½¿ç”¨æ¨¡å‹: {tester.models_config[best_model]['name']}")
    
    # è·å–UIè‡ªåŠ¨åŒ–æ¨èæ¨¡å‹
    ui_models = tester.get_models_by_use_case("UIè‡ªåŠ¨åŒ–")
    if ui_models:
        logger.info(f"ğŸ¤– UIè‡ªåŠ¨åŒ–æ¨è: {tester.models_config[ui_models[0]]['name']}")
    
    return results


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæµ‹è¯•
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    
    asyncio.run(run_ai_model_tests())
