"""
è„šæœ¬ç”Ÿæˆæ™ºèƒ½ä½“ - é‡æ–°è®¾è®¡ç‰ˆæœ¬
ä¸“é—¨è´Ÿè´£å°†æµ‹è¯•ç”¨ä¾‹è½¬æ¢ä¸ºå¯æ‰§è¡Œçš„è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬

æ ¸å¿ƒèŒè´£ï¼š
1. å°†æµ‹è¯•ç”¨ä¾‹è½¬æ¢ä¸ºé«˜è´¨é‡çš„pytestæµ‹è¯•è„šæœ¬
2. ç”Ÿæˆå®Œæ•´çš„æµ‹è¯•é¡¹ç›®ç»“æ„å’Œé…ç½®æ–‡ä»¶
3. é›†æˆæµ‹è¯•æ¡†æ¶å’Œå·¥å…·ï¼ˆpytestã€requestsã€allureç­‰ï¼‰
4. ç¡®ä¿ç”Ÿæˆçš„è„šæœ¬å¯ä»¥ç›´æ¥è¿è¡Œ

æ•°æ®æµï¼šScriptGenerationInput -> è„šæœ¬ç”Ÿæˆ -> ScriptGenerationOutput
"""
import json
import uuid
from datetime import datetime
from typing import List, Dict, Any, Optional
from pathlib import Path

from autogen_core import message_handler, type_subscription, MessageContext, TopicId
from loguru import logger

from app.agents.api_automation.base_api_agent import BaseApiAutomationAgent
from app.core.types import AgentTypes, TopicTypes

# å¯¼å…¥é‡æ–°è®¾è®¡çš„æ•°æ®æ¨¡å‹
from .schemas import (
    ScriptGenerationInput, ScriptGenerationOutput, GeneratedScript,
    GeneratedTestCase, ParsedEndpoint, TestCaseType, AgentPrompts
)


@type_subscription(topic_type=TopicTypes.TEST_SCRIPT_GENERATOR.value)
class ScriptGeneratorAgent(BaseApiAutomationAgent):
    """
    è„šæœ¬ç”Ÿæˆæ™ºèƒ½ä½“ - é‡æ–°è®¾è®¡ç‰ˆæœ¬
    
    ä¸“æ³¨äºç”Ÿæˆé«˜è´¨é‡ã€å¯ç»´æŠ¤çš„è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬ï¼Œ
    ç¡®ä¿æµ‹è¯•ä»£ç çš„ä¸“ä¸šæ€§å’Œå¯æ‰§è¡Œæ€§ã€‚
    """

    def __init__(self, model_client_instance=None, agent_config=None, **kwargs):
        """åˆå§‹åŒ–è„šæœ¬ç”Ÿæˆæ™ºèƒ½ä½“"""
        super().__init__(
            agent_type=AgentTypes.TEST_SCRIPT_GENERATOR,
            model_client_instance=model_client_instance,
            **kwargs
        )

        self.agent_config = agent_config or {}
        self._initialize_assistant_agent()

        # ç”Ÿæˆç»Ÿè®¡æŒ‡æ ‡
        self.generation_metrics = {
            "total_generations": 0,
            "successful_generations": 0,
            "failed_generations": 0,
            "total_scripts_generated": 0,
            "total_test_methods_generated": 0
        }

        # è„šæœ¬ç”Ÿæˆé…ç½®
        self.generation_config = {
            "framework": "pytest",
            "enable_allure": True,
            "enable_data_driven": True,
            "enable_parallel": True,
            "single_script_mode": True,  # æ–°å¢ï¼šå•è„šæœ¬æ¨¡å¼
            "include_fixtures_inline": True,  # æ–°å¢ï¼šå†…è”fixture
            "code_style": "pep8"
        }

        # è¾“å‡ºç›®å½•
        self.output_dir = Path("./generated_tests")
        self.output_dir.mkdir(exist_ok=True)

        logger.info(f"è„šæœ¬ç”Ÿæˆæ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ: {self.agent_name}")

    @message_handler
    async def handle_script_generation_request(
        self,
        message: ScriptGenerationInput,
        ctx: MessageContext
    ) -> None:
        """å¤„ç†è„šæœ¬ç”Ÿæˆè¯·æ±‚ - ä¸»è¦å…¥å£ç‚¹"""
        start_time = datetime.now()
        self.generation_metrics["total_generations"] += 1

        try:
            logger.info(
                f"å¼€å§‹ç”Ÿæˆæµ‹è¯•è„šæœ¬: document_id={message.document_id}, "
                f"interface_id={getattr(message, 'interface_id', None)}, "
                f"æµ‹è¯•ç”¨ä¾‹æ•°é‡: {len(message.test_cases)}, "
                f"ç«¯ç‚¹æ•°é‡: {len(message.endpoints)}, "
                f"ä¾èµ–å…³ç³»æ•°é‡: {len(getattr(message, 'dependencies', []))}"
            )

            # è®°å½•å¼€å§‹ç”Ÿæˆè„šæœ¬çš„æ—¥å¿—
            await self._log_operation_start(
                message.session_id,
                "script_generation",
                {
                    "document_id": message.document_id,
                    "interface_id": getattr(message, 'interface_id', None),
                    "test_cases_count": len(message.test_cases),
                    "endpoints_count": len(message.endpoints),
                    "dependencies_count": len(getattr(message, 'dependencies', []))
                }
            )

            await self._log_operation_progress(
                message.session_id,
                "script_generation",
                "æ™ºèƒ½ç”Ÿæˆæµ‹è¯•è„šæœ¬"
            )

            # 1. ä½¿ç”¨å¤§æ¨¡å‹æ™ºèƒ½ç”Ÿæˆæµ‹è¯•è„šæœ¬
            generation_result = await self._intelligent_generate_scripts(
                message.api_info,
                message.endpoints,
                message.test_cases,
                getattr(message, 'dependencies', []),  # å¤„ç†ä¾èµ–å…³ç³»
                message.execution_groups,
                message.generation_options  # ä½¿ç”¨ä¼ é€’çš„ç”Ÿæˆé€‰é¡¹
            )
            
            await self._log_operation_progress(
                message.session_id,
                "script_generation",
                "æ„å»ºè„šæœ¬å¯¹è±¡",
                {"scripts_count": len(generation_result.get("scripts", []))}
            )

            # 2. æ„å»ºè„šæœ¬å¯¹è±¡ï¼ˆå•è„šæœ¬æ¨¡å¼ï¼‰
            scripts = self._build_script_objects(
                generation_result.get("scripts", []), message.test_cases
            )

            await self._log_operation_progress(
                message.session_id,
                "script_generation",
                "ç”Ÿæˆé…ç½®æ–‡ä»¶"
            )

            # 3. ç®€åŒ–é…ç½®ï¼ˆä»…ç”Ÿæˆå¿…è¦çš„é…ç½®ä¿¡æ¯ï¼‰
            config_files = {}  # ä¸å†ç”Ÿæˆé¢å¤–çš„é…ç½®æ–‡ä»¶
            requirements_txt = self._generate_requirements_txt()
            readme_content = self._generate_simple_readme_content(message.api_info, scripts)
            
            # 6. ç”Ÿæˆæ‘˜è¦ä¿¡æ¯
            generation_summary = self._generate_summary(scripts, generation_result)
            
            # 7. æ„å»ºè¾“å‡ºç»“æœ
            output = ScriptGenerationOutput(
                session_id=message.session_id,
                document_id=message.document_id,
                interface_id=getattr(message, 'interface_id', None),  # ä¼ é€’interface_id
                scripts=scripts,
                config_files=config_files,
                requirements_txt=requirements_txt,
                readme_content=readme_content,
                generation_summary=generation_summary,
                processing_time=(datetime.now() - start_time).total_seconds()
            )

            # 8. æ›´æ–°ç»Ÿè®¡æŒ‡æ ‡
            self.generation_metrics["successful_generations"] += 1
            self.generation_metrics["total_scripts_generated"] += len(scripts)
            self.generation_metrics["total_test_methods_generated"] += sum(
                len(script.test_case_ids) for script in scripts
            )
            self._update_metrics("script_generation", True, output.processing_time)

            await self._log_operation_progress(
                message.session_id,
                "script_generation",
                "ä¿å­˜ç”Ÿæˆæ–‡ä»¶"
            )

            # 9. ä¿å­˜ç”Ÿæˆçš„æ–‡ä»¶åˆ°ç£ç›˜
            await self._save_generated_files(output)

            await self._log_operation_progress(
                message.session_id,
                "script_generation",
                "å‘é€åˆ°æ•°æ®æŒä¹…åŒ–æ™ºèƒ½ä½“"
            )

            # 10. å‘é€è„šæœ¬åˆ°æ•°æ®æŒä¹…åŒ–æ™ºèƒ½ä½“
            await self._send_to_persistence_agent(output, message, ctx)

            await self._log_operation_complete(
                message.session_id,
                "script_generation",
                {
                    "scripts_count": len(scripts),
                    "processing_time": output.processing_time
                }
            )

            logger.info(f"è„šæœ¬ç”Ÿæˆå®Œæˆ: {message.document_id}, ç”Ÿæˆè„šæœ¬æ•°: {len(scripts)}")

        except Exception as e:
            self.generation_metrics["failed_generations"] += 1
            self._update_metrics("script_generation", False)
            error_info = self._handle_common_error(e, "script_generation")

            await self._log_operation_error(
                message.session_id,
                "script_generation",
                e
            )

            logger.error(f"è„šæœ¬ç”Ÿæˆå¤±è´¥: {error_info}")

    async def _intelligent_generate_scripts(
        self,
        api_info,
        endpoints: List[ParsedEndpoint],
        test_cases: List[GeneratedTestCase],
        dependencies: List = None,
        execution_groups = None,
        generation_options: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """ä½¿ç”¨å¤§æ¨¡å‹æ™ºèƒ½ç”Ÿæˆæµ‹è¯•è„šæœ¬"""
        try:
            # è®¾ç½®é»˜è®¤å€¼
            dependencies = dependencies or []
            execution_groups = execution_groups or []
            generation_options = generation_options or {}

            # æ„å»ºç”Ÿæˆä»»åŠ¡æç¤ºè¯
            api_info_str = json.dumps({
                "title": api_info.title,
                "version": api_info.version,
                "description": api_info.description,
                "base_url": api_info.base_url
            }, indent=2, ensure_ascii=False)

            endpoints_info = self._format_endpoints_for_generation(endpoints)
            test_cases_info = self._format_test_cases_for_generation(test_cases)
            dependencies_info = self._format_dependencies_for_generation(dependencies)
            groups_info = self._format_execution_groups_for_generation(execution_groups)
            options_info = json.dumps(generation_options, indent=2, ensure_ascii=False)

            task_prompt = AgentPrompts.SCRIPT_GENERATOR_TASK_PROMPT.format(
                api_info=api_info_str,
                endpoints=endpoints_info,
                test_cases=test_cases_info,
                dependencies=dependencies_info,
                execution_groups=groups_info,
                generation_options=options_info
            )
            
            # ä½¿ç”¨AssistantAgentè¿›è¡Œæ™ºèƒ½ç”Ÿæˆ
            result_content = await self._run_assistant_agent(task_prompt)
            
            if result_content:
                # æå–JSONç»“æœ
                parsed_data = self._extract_json_from_content(result_content)
                if parsed_data:
                    return parsed_data
            
            # å¦‚æœå¤§æ¨¡å‹ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨ç”Ÿæˆæ–¹æ³•
            logger.warning("å¤§æ¨¡å‹ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨ç”Ÿæˆæ–¹æ³•")
            return await self._fallback_generate_scripts(endpoints, test_cases, dependencies)

        except Exception as e:
            logger.error(f"æ™ºèƒ½è„šæœ¬ç”Ÿæˆå¤±è´¥: {str(e)}")
            return await self._fallback_generate_scripts(endpoints, test_cases, dependencies)

    def _format_endpoints_for_generation(self, endpoints: List[ParsedEndpoint]) -> str:
        """æ ¼å¼åŒ–ç«¯ç‚¹ä¿¡æ¯ç”¨äºç”Ÿæˆ"""
        formatted_endpoints = []
        
        for endpoint in endpoints:
            endpoint_info = {
                "id": endpoint.endpoint_id,
                "path": endpoint.path,
                "method": endpoint.method.value,
                "summary": endpoint.summary,
                "auth_required": endpoint.auth_required,
                "parameters": [
                    {
                        "name": param.name,
                        "location": param.location.value,
                        "type": param.data_type.value,
                        "required": param.required
                    }
                    for param in endpoint.parameters
                ]
            }
            formatted_endpoints.append(endpoint_info)
        
        return json.dumps(formatted_endpoints, indent=2, ensure_ascii=False)

    def _format_test_cases_for_generation(self, test_cases: List[GeneratedTestCase]) -> str:
        """æ ¼å¼åŒ–æµ‹è¯•ç”¨ä¾‹ä¿¡æ¯ç”¨äºç”Ÿæˆ"""
        formatted_cases = []
        
        for case in test_cases:
            case_info = {
                "test_id": case.test_case_id,
                "test_name": case.test_name,
                "endpoint_id": case.endpoint_id,
                "test_type": case.test_type.value,
                "description": case.description,
                "test_data": [
                    {
                        "parameter_name": data.parameter_name,
                        "test_value": data.test_value,
                        "value_description": data.value_description
                    }
                    for data in case.test_data
                ],
                "assertions": [
                    {
                        "assertion_type": assertion.assertion_type.value,
                        "expected_value": assertion.expected_value,
                        "comparison_operator": assertion.comparison_operator,
                        "description": assertion.description
                    }
                    for assertion in case.assertions
                ],
                "setup_steps": case.setup_steps,
                "cleanup_steps": case.cleanup_steps,
                "priority": case.priority,
                "tags": case.tags
            }
            formatted_cases.append(case_info)
        
        return json.dumps(formatted_cases, indent=2, ensure_ascii=False)

    def _format_dependencies_for_generation(self, dependencies) -> str:
        """æ ¼å¼åŒ–ä¾èµ–å…³ç³»ä¿¡æ¯ç”¨äºç”Ÿæˆ"""
        if not dependencies:
            return "[]"

        formatted_deps = []
        for dep in dependencies:
            dep_info = {
                "source_endpoint_id": dep.source_endpoint_id,
                "target_endpoint_id": dep.target_endpoint_id,
                "dependency_type": dep.dependency_type.value if hasattr(dep.dependency_type, 'value') else str(dep.dependency_type),
                "description": dep.description,
                "data_mapping": dep.data_mapping
            }
            formatted_deps.append(dep_info)

        return json.dumps(formatted_deps, indent=2, ensure_ascii=False)

    def _format_execution_groups_for_generation(self, execution_groups) -> str:
        """æ ¼å¼åŒ–æ‰§è¡Œç»„ä¿¡æ¯ç”¨äºç”Ÿæˆ"""
        formatted_groups = []
        
        for group in execution_groups:
            group_info = {
                "group_name": group.group_name,
                "endpoint_ids": group.endpoint_ids,
                "execution_order": group.execution_order,
                "parallel_execution": group.parallel_execution
            }
            formatted_groups.append(group_info)
        
        return json.dumps(formatted_groups, indent=2, ensure_ascii=False)

    def _build_script_objects(
        self, 
        scripts_data: List[Dict[str, Any]], 
        test_cases: List[GeneratedTestCase]
    ) -> List[GeneratedScript]:
        """æ„å»ºè„šæœ¬å¯¹è±¡"""
        scripts = []
        
        for script_data in scripts_data:
            try:
                script = GeneratedScript(
                    script_name=script_data.get("script_name", "test_api.py"),
                    file_path=script_data.get("file_path", "test_api.py"),
                    script_content=script_data.get("script_content", ""),
                    test_case_ids=script_data.get("test_case_ids", []),
                    framework=script_data.get("framework", "pytest"),
                    dependencies=script_data.get("dependencies", []),
                    execution_order=script_data.get("execution_order", 1)
                )
                scripts.append(script)
                
            except Exception as e:
                logger.warning(f"æ„å»ºè„šæœ¬å¯¹è±¡å¤±è´¥: {str(e)}")
                continue
        
        return scripts

    def _generate_config_files(self, api_info, scripts: List[GeneratedScript]) -> Dict[str, str]:
        """ç”Ÿæˆé…ç½®æ–‡ä»¶ï¼ˆå·²åºŸå¼ƒ - å•è„šæœ¬æ¨¡å¼ä¸éœ€è¦é¢å¤–é…ç½®æ–‡ä»¶ï¼‰"""
        # åœ¨å•è„šæœ¬æ¨¡å¼ä¸‹ï¼Œä¸å†ç”Ÿæˆé¢å¤–çš„é…ç½®æ–‡ä»¶
        # æ‰€æœ‰é…ç½®éƒ½å†…åµŒåœ¨æµ‹è¯•è„šæœ¬ä¸­
        return {}

    def _generate_requirements_txt(self) -> str:
        """ç”Ÿæˆä¾èµ–æ–‡ä»¶"""
        requirements = [
            "pytest>=7.0.0",
            "requests>=2.28.0",
            "allure-pytest>=2.12.0",
            "pytest-html>=3.1.0",
            "pytest-xdist>=3.0.0",  # å¹¶è¡Œæ‰§è¡Œ
            "jsonschema>=4.0.0",    # JSONéªŒè¯
            "pyyaml>=6.0",          # YAMLæ”¯æŒ
            "faker>=18.0.0",        # æµ‹è¯•æ•°æ®ç”Ÿæˆ
        ]
        return "\n".join(requirements)

    def _generate_readme_content(self, api_info, scripts: List[GeneratedScript]) -> str:
        """ç”ŸæˆREADMEæ–‡æ¡£"""
        return f"""# {api_info.title} API è‡ªåŠ¨åŒ–æµ‹è¯•

## é¡¹ç›®æè¿°
{api_info.description}

**APIç‰ˆæœ¬**: {api_info.version}
**åŸºç¡€URL**: {api_info.base_url}

## é¡¹ç›®ç»“æ„
```
tests/
â”œâ”€â”€ conftest.py          # pytesté…ç½®
â”œâ”€â”€ api_utils.py         # APIå·¥å…·ç±»
â”œâ”€â”€ pytest.ini          # pytesté…ç½®æ–‡ä»¶
â”œâ”€â”€ requirements.txt     # ä¾èµ–åŒ…
â””â”€â”€ test_*.py           # æµ‹è¯•è„šæœ¬
```

## å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

## è¿è¡Œæµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest test_api.py

# ç”ŸæˆAllureæŠ¥å‘Š
pytest --allure-dir=reports/allure-results
allure serve reports/allure-results
```

## æµ‹è¯•è„šæœ¬è¯´æ˜
{chr(10).join(f"- **{script.script_name}**: åŒ…å« {len(script.test_case_ids)} ä¸ªæµ‹è¯•ç”¨ä¾‹" for script in scripts)}

## æµ‹è¯•æ ‡è®°
- `positive`: æ­£å‘æµ‹è¯•ç”¨ä¾‹
- `negative`: è´Ÿå‘æµ‹è¯•ç”¨ä¾‹  
- `boundary`: è¾¹ç•Œæµ‹è¯•ç”¨ä¾‹
- `security`: å®‰å…¨æµ‹è¯•ç”¨ä¾‹
- `performance`: æ€§èƒ½æµ‹è¯•ç”¨ä¾‹

## æ³¨æ„äº‹é¡¹
1. è¯·ç¡®ä¿APIæœåŠ¡æ­£åœ¨è¿è¡Œ
2. æ ¹æ®å®é™…ç¯å¢ƒä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„base_url
3. å¦‚éœ€è®¤è¯ï¼Œè¯·åœ¨conftest.pyä¸­é…ç½®è®¤è¯ä¿¡æ¯
"""

    def _generate_summary(
        self,
        scripts: List[GeneratedScript],
        generation_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæ‘˜è¦ä¿¡æ¯"""
        return {
            "total_scripts": len(scripts),
            "total_test_methods": sum(len(script.test_case_ids) for script in scripts),
            "generation_method": generation_result.get("generation_method", "intelligent_single_script"),
            "confidence_score": generation_result.get("confidence_score", 0.8),
            "framework": self.generation_config["framework"],
            "script_mode": "single_script",  # æ–°å¢ï¼šæ ‡è¯†å•è„šæœ¬æ¨¡å¼
            "features_enabled": {
                "allure_reporting": self.generation_config["enable_allure"],
                "data_driven_testing": self.generation_config["enable_data_driven"],
                "parallel_execution": self.generation_config["enable_parallel"],
                "inline_fixtures": self.generation_config["include_fixtures_inline"],
                "self_contained": True  # æ–°å¢ï¼šè‡ªåŒ…å«æ ‡è¯†
            },
            "generation_config": self.generation_config,
            "optimization_notes": [
                "ç”Ÿæˆå•ä¸€å®Œæ•´æµ‹è¯•è„šæœ¬",
                "æ‰€æœ‰fixtureå’Œå·¥å…·å‡½æ•°å†…åµŒåœ¨è„šæœ¬ä¸­",
                "æ— éœ€é¢å¤–é…ç½®æ–‡ä»¶",
                "è„šæœ¬å¯ç‹¬ç«‹è¿è¡Œ"
            ]
        }

    async def _fallback_generate_scripts(
        self,
        endpoints: List[ParsedEndpoint],
        test_cases: List[GeneratedTestCase],
        dependencies: List = None
    ) -> Dict[str, Any]:
        """å¤‡ç”¨è„šæœ¬ç”Ÿæˆæ–¹æ³• - ç”Ÿæˆå•ä¸€å®Œæ•´è„šæœ¬"""
        try:
            # ç”Ÿæˆå®Œæ•´çš„è‡ªåŒ…å«æµ‹è¯•è„šæœ¬
            script_content = self._generate_complete_script_template(endpoints, test_cases, dependencies)

            scripts = [{
                "script_name": "test_api_automation.py",
                "file_path": "test_api_automation.py",
                "script_content": script_content,
                "test_case_ids": [tc.test_case_id for tc in test_cases],
                "framework": "pytest",
                "dependencies": ["pytest", "requests", "allure-pytest"],
                "execution_order": 1
            }]

            return {
                "scripts": scripts,
                "confidence_score": 0.7,
                "generation_method": "fallback_single_script"
            }

        except Exception as e:
            logger.error(f"å¤‡ç”¨è„šæœ¬ç”Ÿæˆå¤±è´¥: {str(e)}")
            return {"scripts": [], "confidence_score": 0.3}

    def _generate_complete_script_template(
        self,
        endpoints: List[ParsedEndpoint],
        test_cases: List[GeneratedTestCase],
        dependencies: List = None
    ) -> str:
        """ç”Ÿæˆå®Œæ•´çš„è‡ªåŒ…å«è„šæœ¬æ¨¡æ¿"""
        dependencies = dependencies or []

        # è·å–APIåŸºç¡€URLï¼ˆä»ç¬¬ä¸€ä¸ªç«¯ç‚¹æ¨æ–­ï¼‰
        base_url = "http://localhost:8000"  # é»˜è®¤å€¼
        if endpoints:
            # å°è¯•ä»ç«¯ç‚¹è·¯å¾„æ¨æ–­åŸºç¡€URL
            base_url = "http://localhost:8000"  # å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´

        return f'''"""
APIè‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬ - å®Œæ•´è‡ªåŒ…å«ç‰ˆæœ¬
è‡ªåŠ¨ç”Ÿæˆäº {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

æ­¤è„šæœ¬åŒ…å«æ‰€æœ‰å¿…è¦çš„é…ç½®ã€å·¥å…·å‡½æ•°å’Œæµ‹è¯•ç”¨ä¾‹ï¼Œå¯ä»¥ç‹¬ç«‹è¿è¡Œã€‚

è¿è¡Œæ–¹å¼ï¼š
    pytest test_api_automation.py -v
    pytest test_api_automation.py --allure-dir=reports
"""
import pytest
import requests
import json
import time
from typing import Dict, Any, Optional
from urllib.parse import urljoin

# ============================================================================
# é…ç½®å¸¸é‡
# ============================================================================

API_BASE_URL = "{base_url}"
DEFAULT_TIMEOUT = 30
DEFAULT_HEADERS = {{
    "Content-Type": "application/json",
    "User-Agent": "API-Test-Automation/1.0"
}}

# ============================================================================
# å…¬å…±Fixtureå®šä¹‰
# ============================================================================

@pytest.fixture(scope="session")
def api_config():
    """APIé…ç½®ä¿¡æ¯"""
    return {{
        "base_url": API_BASE_URL,
        "timeout": DEFAULT_TIMEOUT,
        "headers": DEFAULT_HEADERS.copy()
    }}

@pytest.fixture(scope="session")
def api_client(api_config):
    """APIå®¢æˆ·ç«¯ä¼šè¯"""
    session = requests.Session()
    session.headers.update(api_config["headers"])
    return session

@pytest.fixture(scope="function")
def test_data():
    """æµ‹è¯•æ•°æ®"""
    return {{
        "timestamp": int(time.time()),
        "test_id": f"test_{{int(time.time())}}"
    }}

# ============================================================================
# å·¥å…·å‡½æ•°å®šä¹‰
# ============================================================================

def make_request(client: requests.Session, method: str, path: str,
                base_url: str = API_BASE_URL, **kwargs) -> requests.Response:
    """å‘é€HTTPè¯·æ±‚çš„ç»Ÿä¸€æ–¹æ³•"""
    url = urljoin(base_url.rstrip('/') + '/', path.lstrip('/'))

    # è®¾ç½®é»˜è®¤è¶…æ—¶
    if 'timeout' not in kwargs:
        kwargs['timeout'] = DEFAULT_TIMEOUT

    try:
        response = client.request(method.upper(), url, **kwargs)
        return response
    except requests.exceptions.RequestException as e:
        pytest.fail(f"è¯·æ±‚å¤±è´¥: {{method}} {{url}} - {{str(e)}}")

def validate_response_status(response: requests.Response, expected_status: int = 200):
    """éªŒè¯å“åº”çŠ¶æ€ç """
    assert response.status_code == expected_status, \\
        f"æœŸæœ›çŠ¶æ€ç  {{expected_status}}, å®é™…çŠ¶æ€ç  {{response.status_code}}, å“åº”å†…å®¹: {{response.text[:200]}}"

def validate_response_json(response: requests.Response) -> Dict[str, Any]:
    """éªŒè¯å¹¶è¿”å›JSONå“åº”"""
    try:
        return response.json()
    except json.JSONDecodeError:
        pytest.fail(f"å“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼: {{response.text[:200]}}")

def validate_response_time(response: requests.Response, max_time: float = 5.0):
    """éªŒè¯å“åº”æ—¶é—´"""
    response_time = response.elapsed.total_seconds()
    assert response_time <= max_time, \\
        f"å“åº”æ—¶é—´ {{response_time:.2f}}s è¶…è¿‡æœ€å¤§å…è®¸æ—¶é—´ {{max_time}}s"

def validate_json_structure(data: Dict[str, Any], required_fields: list):
    """éªŒè¯JSONç»“æ„åŒ…å«å¿…éœ€å­—æ®µ"""
    for field in required_fields:
        assert field in data, f"å“åº”JSONç¼ºå°‘å¿…éœ€å­—æ®µ: {{field}}"

# ============================================================================
# æµ‹è¯•ç±»å®šä¹‰
# ============================================================================

class TestAPIAutomation:
    """APIè‡ªåŠ¨åŒ–æµ‹è¯•ç±»"""

{self._generate_complete_test_methods(test_cases, endpoints)}
'''

    def _generate_complete_test_methods(self, test_cases: List[GeneratedTestCase], endpoints: List[ParsedEndpoint]) -> str:
        """ç”Ÿæˆå®Œæ•´çš„æµ‹è¯•æ–¹æ³•é›†åˆ"""
        methods = []

        for test_case in test_cases:
            endpoint = next((ep for ep in endpoints if ep.endpoint_id == test_case.endpoint_id), None)
            if not endpoint:
                continue

            method_content = self._generate_single_test_method(test_case, endpoint)
            methods.append(method_content)

        return "\n".join(methods)

    def _generate_single_test_method(self, test_case: GeneratedTestCase, endpoint: ParsedEndpoint) -> str:
        """ç”Ÿæˆå•ä¸ªæµ‹è¯•æ–¹æ³•"""
        method_name = test_case.test_name.replace(" ", "_").replace("-", "_").lower()
        if not method_name.startswith("test_"):
            method_name = f"test_{method_name}"

        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        test_data_setup = self._generate_test_data_setup(test_case)

        # ç”Ÿæˆè¯·æ±‚å‚æ•°
        request_params = self._generate_request_params(test_case, endpoint)

        # ç”Ÿæˆæ–­è¨€
        assertions = self._generate_assertions(test_case)

        # æ£€æŸ¥æ˜¯å¦æœ‰çŠ¶æ€ç æ–­è¨€
        has_status_assertion = any(a.assertion_type.value == "status_code" for a in test_case.assertions)

        return f'''    def {method_name}(self, api_client, api_config, test_data):
        """
        {test_case.description}
        æµ‹è¯•ç±»å‹: {test_case.test_type.value}
        ç«¯ç‚¹: {endpoint.method.value} {endpoint.path}
        """
        # æµ‹è¯•æ•°æ®å‡†å¤‡
{test_data_setup}

        # å‘é€è¯·æ±‚
        response = make_request(
            api_client,
            "{endpoint.method.value}",
            "{endpoint.path}",
            api_config["base_url"],
{request_params}
        )

        # åŸºç¡€éªŒè¯
        {"# çŠ¶æ€ç éªŒè¯åœ¨è‡ªå®šä¹‰æ–­è¨€ä¸­è¿›è¡Œ" if has_status_assertion else "validate_response_status(response, 200)"}
        validate_response_time(response, 5.0)

{assertions}

        # è®°å½•æµ‹è¯•ç»“æœ
        print(f"âœ… {{test_data['test_id']}} - {test_case.test_name} æµ‹è¯•é€šè¿‡")
'''

    def _generate_test_data_setup(self, test_case: GeneratedTestCase) -> str:
        """ç”Ÿæˆæµ‹è¯•æ•°æ®è®¾ç½®ä»£ç """
        if not test_case.test_data:
            return "        # æ— éœ€ç‰¹æ®Šæµ‹è¯•æ•°æ®"

        setup_lines = []
        for data_item in test_case.test_data:
            # ç¡®ä¿å˜é‡åç¬¦åˆPythonå‘½åè§„èŒƒ
            var_name = data_item.parameter_name.replace("-", "_").replace(".", "_")
            # ç¡®ä¿å˜é‡åæ˜¯æœ‰æ•ˆçš„Pythonæ ‡è¯†ç¬¦
            if not var_name.isidentifier():
                var_name = f"param_{var_name}"

            setup_lines.append(f'        {var_name} = "{data_item.test_value}"  # {data_item.value_description}')

        return "\n".join(setup_lines)

    def _generate_request_params(self, test_case: GeneratedTestCase, endpoint: ParsedEndpoint) -> str:
        """ç”Ÿæˆè¯·æ±‚å‚æ•°ä»£ç """
        params = []

        # æ„å»ºè¯·æ±‚ä½“æ•°æ®
        if test_case.test_data and endpoint.method.value in ["POST", "PUT", "PATCH"]:
            json_fields = []
            header_fields = []

            for data_item in test_case.test_data:
                var_name = data_item.parameter_name.replace("-", "_").replace(".", "_")
                if not var_name.isidentifier():
                    var_name = f"param_{var_name}"

                # åŒºåˆ†è¯·æ±‚ä½“å‚æ•°å’Œheaderå‚æ•°
                if data_item.parameter_name.lower() in ['access-token', 'fecshop-currency', 'fecshop-lang']:
                    # è¿™äº›æ˜¯headerå‚æ•°
                    header_key = data_item.parameter_name
                    header_fields.append(f'"{header_key}": {var_name}')
                else:
                    # è¿™äº›æ˜¯è¯·æ±‚ä½“å‚æ•°
                    json_fields.append(f'"{data_item.parameter_name}": {var_name}')

            if json_fields:
                json_data = "{" + ", ".join(json_fields) + "}"
                params.append(f'            json={json_data},')

            if header_fields:
                headers_data = "{" + ", ".join(header_fields) + "}"
                params.append(f'            headers={headers_data}')

        # æ ¹æ®ç«¯ç‚¹å‚æ•°ç±»å‹ç”Ÿæˆå…¶ä»–å‚æ•°
        has_query_params = any(p.location.value == "query" for p in endpoint.parameters)

        if has_query_params and not any("params=" in p for p in params):
            params.append('            # params={}  # æŸ¥è¯¢å‚æ•°ï¼ˆå¦‚éœ€è¦ï¼‰')

        if not params:
            params.append('            # æ— éœ€é¢å¤–å‚æ•°')

        return "\n".join(params)

    def _generate_assertions(self, test_case: GeneratedTestCase) -> str:
        """ç”Ÿæˆæ–­è¨€ä»£ç """
        if not test_case.assertions:
            return """        # è‡ªå®šä¹‰æ–­è¨€éªŒè¯
        response_data = validate_response_json(response)
        assert response_data is not None"""

        assertion_lines = ["        # è‡ªå®šä¹‰æ–­è¨€éªŒè¯"]
        assertion_lines.append("        response_data = validate_response_json(response)")

        # æ£€æŸ¥æ˜¯å¦æœ‰çŠ¶æ€ç æ–­è¨€ï¼Œé¿å…é‡å¤éªŒè¯
        has_status_assertion = any(a.assertion_type.value == "status_code" for a in test_case.assertions)

        for assertion in test_case.assertions:
            if assertion.assertion_type.value == "status_code":
                # åªåœ¨è¿™é‡ŒéªŒè¯çŠ¶æ€ç ï¼Œä¸åœ¨åŸºç¡€éªŒè¯ä¸­é‡å¤
                assertion_lines.append(f'        validate_response_status(response, {assertion.expected_value})')
            elif assertion.assertion_type.value == "json_field":
                assertion_lines.append(f'        assert "{assertion.expected_value}" in response_data  # {assertion.description}')
            elif assertion.assertion_type.value == "response_time":
                assertion_lines.append(f'        validate_response_time(response, {assertion.expected_value})')

        return "\n".join(assertion_lines)

    def _generate_simple_readme_content(self, api_info, scripts: List[GeneratedScript]) -> str:
        """ç”Ÿæˆç®€åŒ–çš„READMEæ–‡æ¡£"""
        script_name = scripts[0].script_name if scripts else "test_api_automation.py"
        total_tests = sum(len(script.test_case_ids) for script in scripts)

        return f"""# {api_info.title} API è‡ªåŠ¨åŒ–æµ‹è¯•

## é¡¹ç›®æè¿°
{api_info.description}

**APIç‰ˆæœ¬**: {api_info.version}
**åŸºç¡€URL**: {api_info.base_url}

## æµ‹è¯•è„šæœ¬
- **{script_name}**: åŒ…å« {total_tests} ä¸ªæµ‹è¯•ç”¨ä¾‹çš„å®Œæ•´è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–
```bash
pip install pytest requests allure-pytest
```

### 2. è¿è¡Œæµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest {script_name} -v

# ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
pytest {script_name} -v --tb=short

# ç”ŸæˆAllureæŠ¥å‘Š
pytest {script_name} --allure-dir=reports
allure serve reports
```

### 3. æµ‹è¯•é…ç½®
æµ‹è¯•è„šæœ¬æ˜¯å®Œå…¨è‡ªåŒ…å«çš„ï¼Œæ‰€æœ‰é…ç½®éƒ½åœ¨è„šæœ¬å†…éƒ¨å®šä¹‰ã€‚
å¦‚éœ€ä¿®æ”¹APIåŸºç¡€URLï¼Œè¯·ç¼–è¾‘è„šæœ¬ä¸­çš„ `API_BASE_URL` å¸¸é‡ã€‚

## æ³¨æ„äº‹é¡¹
1. ç¡®ä¿APIæœåŠ¡æ­£åœ¨è¿è¡Œ
2. æ ¹æ®å®é™…ç¯å¢ƒä¿®æ”¹è„šæœ¬ä¸­çš„API_BASE_URL
3. å¦‚éœ€è®¤è¯ï¼Œè¯·åœ¨è„šæœ¬ä¸­çš„api_config fixtureä¸­æ·»åŠ è®¤è¯ä¿¡æ¯

## æµ‹è¯•ç‰¹æ€§
- âœ… å®Œæ•´çš„HTTPè¯·æ±‚æµ‹è¯•
- âœ… å“åº”çŠ¶æ€ç éªŒè¯
- âœ… JSONå“åº”ç»“æ„éªŒè¯
- âœ… å“åº”æ—¶é—´æ€§èƒ½éªŒè¯
- âœ… è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œæ—¥å¿—
- âœ… æ”¯æŒAllureæµ‹è¯•æŠ¥å‘Š
"""

    async def _save_generated_files(self, output: ScriptGenerationOutput):
        """ä¿å­˜ç”Ÿæˆçš„æ–‡ä»¶åˆ°ç£ç›˜ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            # åˆ›å»ºé¡¹ç›®ç›®å½•
            project_dir = self.output_dir / f"api_test_{output.interface_id[:8]}"
            project_dir.mkdir(exist_ok=True)

            # ä¿å­˜æµ‹è¯•è„šæœ¬ï¼ˆä¸»è¦æ–‡ä»¶ï¼‰
            for script in output.scripts:
                script_path = project_dir / script.file_path
                script_path.write_text(script.script_content, encoding='utf-8')
                logger.info(f"å·²ä¿å­˜æµ‹è¯•è„šæœ¬: {script_path}")

            # ä¿å­˜ä¾èµ–æ–‡ä»¶
            if output.requirements_txt:
                requirements_path = project_dir / "requirements.txt"
                requirements_path.write_text(output.requirements_txt, encoding='utf-8')
                logger.info(f"å·²ä¿å­˜ä¾èµ–æ–‡ä»¶: {requirements_path}")

            # ä¿å­˜README
            if output.readme_content:
                readme_path = project_dir / "README.md"
                readme_path.write_text(output.readme_content, encoding='utf-8')
                logger.info(f"å·²ä¿å­˜READMEæ–‡æ¡£: {readme_path}")

            logger.info(f"âœ… å•è„šæœ¬æµ‹è¯•é¡¹ç›®å·²ä¿å­˜åˆ°: {project_dir}")
            logger.info(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶: {len(output.scripts)} ä¸ªè„šæœ¬æ–‡ä»¶")

        except Exception as e:
            logger.error(f"ä¿å­˜ç”Ÿæˆæ–‡ä»¶å¤±è´¥: {str(e)}")

    def get_generation_statistics(self) -> Dict[str, Any]:
        """è·å–ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        base_stats = self.get_common_statistics()
        base_stats.update({
            "generation_metrics": self.generation_metrics,
            "generation_config": self.generation_config,
            "avg_scripts_per_generation": (
                self.generation_metrics["total_scripts_generated"] / 
                max(self.generation_metrics["successful_generations"], 1)
            ),
            "avg_methods_per_script": (
                self.generation_metrics["total_test_methods_generated"] / 
                max(self.generation_metrics["total_scripts_generated"], 1)
            )
        })
        return base_stats

    async def _send_to_persistence_agent(self, output: ScriptGenerationOutput, message: ScriptGenerationInput, ctx: MessageContext):
        """å‘é€è„šæœ¬åˆ°æ•°æ®æŒä¹…åŒ–æ™ºèƒ½ä½“"""
        try:
            from .schemas import ScriptPersistenceInput

            # æ„å»ºè„šæœ¬æŒä¹…åŒ–è¾“å…¥
            persistence_input = ScriptPersistenceInput(
                session_id=output.session_id,
                document_id=output.document_id,
                interface_id=message.interface_id,
                scripts=output.scripts,
                config_files=output.config_files,
                requirements_txt=output.requirements_txt,
                readme_content=output.readme_content,
                generation_summary=output.generation_summary,
                processing_time=output.processing_time
            )

            # å‘é€åˆ°æ•°æ®æŒä¹…åŒ–æ™ºèƒ½ä½“
            await self.runtime.publish_message(
                persistence_input,
                topic_id=TopicId(type=TopicTypes.API_DATA_PERSISTENCE.value, source=self.agent_name)
            )

            logger.info(f"å·²å‘é€è„šæœ¬åˆ°æ•°æ®æŒä¹…åŒ–æ™ºèƒ½ä½“: {output.document_id}")

        except Exception as e:
            logger.error(f"å‘é€è„šæœ¬åˆ°æ•°æ®æŒä¹…åŒ–æ™ºèƒ½ä½“å¤±è´¥: {str(e)}")
