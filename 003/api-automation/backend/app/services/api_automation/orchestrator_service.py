"""
æ¥å£è‡ªåŠ¨åŒ–æ™ºèƒ½ä½“ç¼–æ’æœåŠ¡
è´Ÿè´£åè°ƒå„ä¸ªæ™ºèƒ½ä½“çš„å·¥ä½œæµç¨‹
"""
from typing import Dict, List, Any, Optional
from datetime import datetime

from autogen_core import SingleThreadedAgentRuntime, TopicId
from loguru import logger

from app.core.agents.collector import StreamResponseCollector
from app.core.types import AgentPlatform, TopicTypes
from app.core.messages.api_automation import (
    ApiDocParseRequest, DependencyAnalysisRequest,
    TestScriptGenerationRequest, TestExecutionRequest,
    LogRecordRequest
)
from app.core.enums import LogLevel
from app.agents.factory import agent_factory


class ApiAutomationOrchestrator:
    """
    æ¥å£è‡ªåŠ¨åŒ–æ™ºèƒ½ä½“ç¼–æ’å™¨
    
    è´Ÿè´£åè°ƒä»¥ä¸‹æ™ºèƒ½ä½“çš„å·¥ä½œæµç¨‹ï¼š
    1. APIæ–‡æ¡£è§£ææ™ºèƒ½ä½“ - è§£æAPIæ–‡æ¡£
    2. æ¥å£ä¾èµ–åˆ†ææ™ºèƒ½ä½“ - åˆ†ææ¥å£ä¾èµ–å…³ç³»
    3. æµ‹è¯•è„šæœ¬ç”Ÿæˆæ™ºèƒ½ä½“ - ç”Ÿæˆpytestæµ‹è¯•è„šæœ¬
    4. æµ‹è¯•æ‰§è¡Œæ™ºèƒ½ä½“ - æ‰§è¡Œæµ‹è¯•å¹¶ç”ŸæˆæŠ¥å‘Š
    5. æ—¥å¿—è®°å½•æ™ºèƒ½ä½“ - è®°å½•æ‰§è¡Œæ—¥å¿—
    """

    def __init__(self, collector: Optional[StreamResponseCollector] = None):
        """
        åˆå§‹åŒ–æ¥å£è‡ªåŠ¨åŒ–ç¼–æ’å™¨
        
        Args:
            collector: å¯é€‰çš„StreamResponseCollectorç”¨äºæ•è·æ™ºèƒ½ä½“å“åº”
        """
        self.response_collector = collector or StreamResponseCollector(
            platform=AgentPlatform.API_AUTOMATION
        )
        self.runtime: Optional[SingleThreadedAgentRuntime] = None
        self.agent_factory = agent_factory
        self.active_sessions: Dict[str, Dict[str, Any]] = {}
        
        # ç¼–æ’å™¨æ€§èƒ½æŒ‡æ ‡
        self.orchestrator_metrics = {
            "total_workflows": 0,
            "successful_workflows": 0,
            "failed_workflows": 0,
            "active_sessions": 0
        }
        
        logger.info("æ¥å£è‡ªåŠ¨åŒ–æ™ºèƒ½ä½“ç¼–æ’å™¨åˆå§‹åŒ–å®Œæˆ")

    async def initialize(self, **agent_kwargs) -> None:
        """
        åˆå§‹åŒ–ç¼–æ’å™¨å’Œæ™ºèƒ½ä½“
        
        Args:
            **agent_kwargs: æ™ºèƒ½ä½“åˆå§‹åŒ–å‚æ•°
        """
        try:
            logger.info("ğŸš€ åˆå§‹åŒ–æ¥å£è‡ªåŠ¨åŒ–æ™ºèƒ½ä½“ç¼–æ’å™¨...")
            
            if self.runtime is None:
                # åˆ›å»ºè¿è¡Œæ—¶
                self.runtime = SingleThreadedAgentRuntime()
                
                # æ³¨å†Œæ™ºèƒ½ä½“åˆ°è¿è¡Œæ—¶
                await self.agent_factory.register_agents_to_runtime(self.runtime)
                
                # è®¾ç½®å“åº”æ”¶é›†å™¨
                await self.agent_factory.register_stream_collector(
                    runtime=self.runtime,
                    collector=self.response_collector
                )
                
                # å¯åŠ¨è¿è¡Œæ—¶
                self.runtime.start()
                
                logger.info("âœ… æ¥å£è‡ªåŠ¨åŒ–æ™ºèƒ½ä½“ç¼–æ’å™¨åˆå§‹åŒ–å®Œæˆ")
                
        except Exception as e:
            logger.error(f"âŒ æ¥å£è‡ªåŠ¨åŒ–æ™ºèƒ½ä½“ç¼–æ’å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise

    async def process_api_document(
        self, 
        session_id: str,
        file_path: str,
        file_name: str,
        file_content: Optional[str] = None,
        doc_format: str = "auto",
        config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        å¤„ç†APIæ–‡æ¡£çš„å®Œæ•´æµç¨‹
        
        Args:
            session_id: ä¼šè¯ID
            file_path: æ–‡ä»¶è·¯å¾„
            file_name: æ–‡ä»¶å
            file_content: æ–‡ä»¶å†…å®¹ï¼ˆå¯é€‰ï¼‰
            doc_format: æ–‡æ¡£æ ¼å¼
            config: é…ç½®å‚æ•°
            
        Returns:
            Dict[str, Any]: å¤„ç†ç»“æœ
        """
        try:
            self.orchestrator_metrics["total_workflows"] += 1
            self.orchestrator_metrics["active_sessions"] += 1
            
            # è®°å½•ä¼šè¯ä¿¡æ¯
            self.active_sessions[session_id] = {
                "start_time": datetime.now(),
                "status": "processing",
                "current_step": "document_parsing",
                "file_name": file_name,
                "config": config or {}
            }
            
            logger.info(f"å¼€å§‹å¤„ç†APIæ–‡æ¡£: {file_name} (ä¼šè¯: {session_id})")
            
            # è®°å½•å¼€å§‹æ—¥å¿—
            await self._log_workflow_event(
                session_id, 
                "workflow_started", 
                f"å¼€å§‹å¤„ç†APIæ–‡æ¡£: {file_name}",
                {"file_path": file_path, "doc_format": doc_format}
            )
            
            # æ­¥éª¤1: è§£æAPIæ–‡æ¡£
            await self._parse_api_document(
                session_id, file_path, file_name, file_content, doc_format, config
            )
            
            # æ›´æ–°ä¼šè¯çŠ¶æ€
            self.active_sessions[session_id]["current_step"] = "completed"
            self.active_sessions[session_id]["status"] = "completed"
            self.active_sessions[session_id]["end_time"] = datetime.now()
            
            self.orchestrator_metrics["successful_workflows"] += 1
            self.orchestrator_metrics["active_sessions"] -= 1
            
            # è®°å½•å®Œæˆæ—¥å¿—
            await self._log_workflow_event(
                session_id,
                "workflow_completed",
                f"APIæ–‡æ¡£å¤„ç†å®Œæˆ: {file_name}",
                {"duration": (datetime.now() - self.active_sessions[session_id]["start_time"]).total_seconds()}
            )
            
            return {
                "success": True,
                "session_id": session_id,
                "message": "APIæ–‡æ¡£å¤„ç†å®Œæˆ",
                "session_info": self.active_sessions[session_id]
            }
            
        except Exception as e:
            self.orchestrator_metrics["failed_workflows"] += 1
            self.orchestrator_metrics["active_sessions"] -= 1
            
            # æ›´æ–°ä¼šè¯çŠ¶æ€
            if session_id in self.active_sessions:
                self.active_sessions[session_id]["status"] = "failed"
                self.active_sessions[session_id]["error"] = str(e)
                self.active_sessions[session_id]["end_time"] = datetime.now()
            
            # è®°å½•é”™è¯¯æ—¥å¿—
            await self._log_workflow_event(
                session_id,
                "workflow_failed",
                f"APIæ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}",
                {"error": str(e), "file_name": file_name}
            )
            
            logger.error(f"å¤„ç†APIæ–‡æ¡£å¤±è´¥: {str(e)}")
            raise

    async def _parse_api_document(
        self,
        session_id: str,
        file_path: str,
        file_name: str,
        file_content: Optional[str],
        doc_format: str,
        config: Optional[Dict[str, Any]]
    ) -> None:
        """å‘é€APIæ–‡æ¡£è§£æè¯·æ±‚"""
        try:
            # æ„å»ºè§£æè¯·æ±‚
            parse_request = ApiDocParseRequest(
                session_id=session_id,
                file_path=file_path,
                file_name=file_name,
                file_content=file_content,
                doc_format=doc_format,
                parse_config=config or {}
            )
            
            # å‘é€åˆ°APIæ–‡æ¡£è§£ææ™ºèƒ½ä½“
            await self.runtime.publish_message(
                parse_request,
                topic_id=TopicId(type=TopicTypes.API_DOC_PARSER.value, source="orchestrator")
            )
            
            logger.info(f"å·²å‘é€APIæ–‡æ¡£è§£æè¯·æ±‚: {session_id}")
            
        except Exception as e:
            logger.error(f"å‘é€APIæ–‡æ¡£è§£æè¯·æ±‚å¤±è´¥: {str(e)}")
            raise

    async def execute_test_suite(
        self,
        session_id: str,
        script_files: List[str],
        test_config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œæµ‹è¯•å¥—ä»¶
        
        Args:
            session_id: ä¼šè¯ID
            script_files: æµ‹è¯•è„šæœ¬æ–‡ä»¶åˆ—è¡¨
            test_config: æµ‹è¯•é…ç½®
            
        Returns:
            Dict[str, Any]: æ‰§è¡Œç»“æœ
        """
        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œæµ‹è¯•å¥—ä»¶: {session_id}")
            
            # æ„å»ºæ‰§è¡Œè¯·æ±‚
            execution_request = TestExecutionRequest(
                session_id=session_id,
                doc_id=session_id,  # ç®€åŒ–å¤„ç†
                test_cases=[],  # å°†åœ¨æ‰§è¡Œæ™ºèƒ½ä½“ä¸­å¤„ç†
                script_files=script_files,
                execution_config=test_config or {
                    "framework": "pytest",
                    "parallel": False,
                    "max_workers": 1,
                    "timeout": 300,
                    "report_formats": ["allure", "html"]
                },
                environment="test",
                parallel=test_config.get("parallel", False) if test_config else False,
                max_workers=test_config.get("max_workers", 1) if test_config else 1
            )
            
            # å‘é€åˆ°æµ‹è¯•æ‰§è¡Œæ™ºèƒ½ä½“
            await self.runtime.publish_message(
                execution_request,
                topic_id=TopicId(type=TopicTypes.TEST_EXECUTOR.value, source="orchestrator")
            )
            
            # è®°å½•æ‰§è¡Œæ—¥å¿—
            await self._log_workflow_event(
                session_id,
                "test_execution_started",
                f"å¼€å§‹æ‰§è¡Œæµ‹è¯•å¥—ä»¶ï¼ŒåŒ…å« {len(script_files)} ä¸ªè„šæœ¬æ–‡ä»¶",
                {"script_files": script_files, "config": test_config}
            )
            
            return {
                "success": True,
                "session_id": session_id,
                "message": "æµ‹è¯•æ‰§è¡Œå·²å¯åŠ¨",
                "script_count": len(script_files)
            }
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œæµ‹è¯•å¥—ä»¶å¤±è´¥: {str(e)}")
            await self._log_workflow_event(
                session_id,
                "test_execution_failed",
                f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}",
                {"error": str(e)}
            )
            raise

    async def get_session_status(self, session_id: str) -> Dict[str, Any]:
        """
        è·å–ä¼šè¯çŠ¶æ€
        
        Args:
            session_id: ä¼šè¯ID
            
        Returns:
            Dict[str, Any]: ä¼šè¯çŠ¶æ€ä¿¡æ¯
        """
        try:
            if session_id not in self.active_sessions:
                return {
                    "success": False,
                    "message": "ä¼šè¯ä¸å­˜åœ¨",
                    "session_id": session_id
                }
            
            session_info = self.active_sessions[session_id].copy()
            
            # æ·»åŠ è¿è¡Œæ—¶é—´
            if "start_time" in session_info:
                if session_info.get("status") == "processing":
                    session_info["running_time"] = (
                        datetime.now() - session_info["start_time"]
                    ).total_seconds()
                elif "end_time" in session_info:
                    session_info["total_time"] = (
                        session_info["end_time"] - session_info["start_time"]
                    ).total_seconds()
            
            return {
                "success": True,
                "session_id": session_id,
                "session_info": session_info
            }
            
        except Exception as e:
            logger.error(f"è·å–ä¼šè¯çŠ¶æ€å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": str(e),
                "session_id": session_id
            }

    async def get_orchestrator_metrics(self) -> Dict[str, Any]:
        """è·å–ç¼–æ’å™¨æŒ‡æ ‡"""
        try:
            # è·å–æ™ºèƒ½ä½“å¥åº·çŠ¶æ€
            agent_health = await self.agent_factory.health_check_all()
            
            # è·å–æ€§èƒ½æ‘˜è¦
            performance_summary = await self.agent_factory.get_performance_summary()
            
            return {
                "orchestrator_metrics": self.orchestrator_metrics,
                "agent_health": agent_health,
                "performance_summary": performance_summary,
                "active_sessions_count": len(self.active_sessions),
                "active_sessions": list(self.active_sessions.keys()),
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"è·å–ç¼–æ’å™¨æŒ‡æ ‡å¤±è´¥: {str(e)}")
            return {"error": str(e)}

    async def _log_workflow_event(
        self,
        session_id: str,
        event_type: str,
        message: str,
        data: Dict[str, Any]
    ) -> None:
        """è®°å½•å·¥ä½œæµäº‹ä»¶æ—¥å¿—"""
        try:
            log_request = LogRecordRequest(
                session_id=session_id,
                agent_name="ApiAutomationOrchestrator",
                log_level=LogLevel.INFO.value,
                log_message=message,
                log_data=data,
                execution_context={
                    "event_type": event_type,
                    "orchestrator": "api_automation"
                }
            )
            
            await self.runtime.publish_message(
                log_request,
                topic_id=TopicId(type=TopicTypes.LOG_RECORDER.value, source="orchestrator")
            )
            
        except Exception as e:
            logger.error(f"è®°å½•å·¥ä½œæµäº‹ä»¶å¤±è´¥: {str(e)}")

    async def cleanup(self) -> None:
        """æ¸…ç†ç¼–æ’å™¨èµ„æº"""
        try:
            # æ¸…ç†æ™ºèƒ½ä½“
            await self.agent_factory.cleanup_all()
            
            # æ¸…ç†å“åº”æ”¶é›†å™¨
            if self.response_collector:
                self.response_collector.cleanup()
            
            # åœæ­¢è¿è¡Œæ—¶
            if self.runtime:
                self.runtime.stop()
            
            # æ¸…ç†ä¼šè¯
            self.active_sessions.clear()
            
            logger.info("æ¥å£è‡ªåŠ¨åŒ–ç¼–æ’å™¨èµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ¸…ç†ç¼–æ’å™¨èµ„æºå¤±è´¥: {str(e)}")

    def get_factory_status(self) -> Dict[str, Any]:
        """è·å–å·¥å‚çŠ¶æ€"""
        return self.agent_factory.get_factory_status()
